{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20203c0f",
   "metadata": {},
   "source": [
    "# I. Project Team Members"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aa3d7f4",
   "metadata": {},
   "source": [
    "| Prepared by | Email | Prepared for |\n",
    "| :-: | :-: | :-: |\n",
    "| **Hardefa Rogonondo** | hardefarogonondo@gmail.com | **IBRD Credit Scorecard Predictive Engine** |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b05cd469",
   "metadata": {},
   "source": [
    "# II. Notebook Target Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47bae1d2",
   "metadata": {},
   "source": [
    "This notebook delineates the model training and evaluation stage of IBRD Credit Scorecard Predictive Engine Project. Here, we train and test predictive models on our preprocessed and feature-engineered loan data. We leverage metrics such as confusion matrix, ROC-AUC, and F1 score to gauge model performance. The trade-offs between various types of prediction errors are evaluated to choose the most suitable model, in line with our business needs. The result is a robust model capable of effectively predicting loans most likely to be cancelled or terminated, fostering more informed loan management decisions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3213f42d",
   "metadata": {},
   "source": [
    "# III. Notebook Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb5c3810",
   "metadata": {},
   "source": [
    "## III.A. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "import hashlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7291e85b",
   "metadata": {},
   "source": [
    "## III.B. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f425995",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../../data/processed/X_train_ohe.pkl')\n",
    "X_test = pd.read_pickle('../../data/processed/X_test_ohe.pkl')\n",
    "y_train = pd.read_pickle('../../data/processed/y_train.pkl')\n",
    "y_test = pd.read_pickle('../../data/processed/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59e32c9",
   "metadata": {},
   "source": [
    "# IV. Models Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db0a5756",
   "metadata": {},
   "source": [
    "## IV.A. Data Shape Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3389b1bf",
   "metadata": {},
   "source": [
    "## IV.B. Data Information Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe621948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aef8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce34b86f",
   "metadata": {},
   "source": [
    "## IV.C. Training Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d26f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "    return datetime.now()\n",
    "\n",
    "def create_logger():\n",
    "    return {\n",
    "        \"model_name\": [],\n",
    "        \"model_uid\": [],\n",
    "        \"training_time\": [],\n",
    "        \"training_date\": [],\n",
    "        \"performance\": [],\n",
    "        \"f1_score_avg\": [],\n",
    "        \"data_configurations\": []\n",
    "    }\n",
    "\n",
    "def training_log_updater(current_log, log_path):\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "    last_log.append(current_log)\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "    return last_log\n",
    "\n",
    "def model_training_and_evaluation(models_list, model_prefix, X_train, y_train, X_test, y_test, data_configuration, log_path):\n",
    "    logger = create_logger()\n",
    "    for model in tqdm(models_list):\n",
    "        model_name = model_prefix + \"-\" + model[\"model_name\"]\n",
    "        start_time = time_stamp()\n",
    "        model[\"model_object\"].fit(X_train, y_train)\n",
    "        finished_time = time_stamp()\n",
    "        elapsed_time = (finished_time - start_time).total_seconds()\n",
    "        y_prediction = model[\"model_object\"].predict(X_test)\n",
    "        performance = classification_report(y_test, y_prediction, output_dict = True)\n",
    "        original_id = str(start_time) + str(finished_time)\n",
    "        hashed_id = hashlib.md5(original_id.encode()).hexdigest()\n",
    "        model[\"model_uid\"] = hashed_id\n",
    "        logger[\"model_name\"].append(model_name)\n",
    "        logger[\"model_uid\"].append(hashed_id)\n",
    "        logger[\"training_time\"].append(elapsed_time)\n",
    "        logger[\"training_date\"].append(str(start_time))\n",
    "        logger[\"performance\"].append(performance)\n",
    "        logger[\"f1_score_avg\"].append(performance[\"macro avg\"][\"f1-score\"])\n",
    "        logger[\"data_configurations\"].append(data_configuration)\n",
    "    training_log = training_log_updater(logger, log_path)\n",
    "    return training_log, models_list\n",
    "\n",
    "def training_log_to_df_converter(training_log):\n",
    "    all_training_logs_df = pd.DataFrame()\n",
    "    for log in tqdm(training_log):\n",
    "        individual_log_df = pd.DataFrame(log)\n",
    "        performance_df = pd.json_normalize(individual_log_df[\"performance\"])\n",
    "        individual_log_df = pd.concat([individual_log_df.drop(\"performance\", axis = 1), performance_df], axis = 1)\n",
    "        all_training_logs_df = pd.concat([all_training_logs_df, individual_log_df])\n",
    "    all_training_logs_df.sort_values([\"f1_score_avg\", \"training_time\"], ascending = [False, True], inplace = True)\n",
    "    all_training_logs_df.reset_index(inplace = True, drop = True)\n",
    "    return all_training_logs_df\n",
    "\n",
    "def best_model_finder(all_training_logs_df, models_list):\n",
    "    model_object = None\n",
    "    best_model_info = all_training_logs_df.iloc[0]\n",
    "    for configuration_data in models_list:\n",
    "        for model_data in models_list[configuration_data]:\n",
    "            if model_data[\"model_uid\"] == best_model_info[\"model_uid\"]:\n",
    "                model_object = model_data[\"model_object\"]\n",
    "                break\n",
    "    if model_object == None:\n",
    "        raise RuntimeError(\"The best model not found in your list of model.\")\n",
    "    return model_object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69eefd12",
   "metadata": {},
   "source": [
    "## IV.D. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68192643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again\n",
    "log_reg_baseline = LogisticRegression()\n",
    "decision_tree_baseline = DecisionTreeClassifier()\n",
    "random_forest_baseline = RandomForestClassifier()\n",
    "xgb_baseline = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = {\n",
    "    \"vanilla\": [\n",
    "        {\"model_name\": log_reg_baseline.__class__.__name__, \"model_object\": log_reg_baseline, \"model_uid\": \"\"},\n",
    "        {\"model_name\": decision_tree_baseline.__class__.__name__, \"model_object\": decision_tree_baseline, \"model_uid\": \"\"},\n",
    "        {\"model_name\": random_forest_baseline.__class__.__name__, \"model_object\": random_forest_baseline, \"model_uid\": \"\"},\n",
    "        {\"model_name\": xgb_baseline.__class__.__name__, \"model_object\": xgb_baseline, \"model_uid\": \"\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a98cf1f",
   "metadata": {},
   "source": [
    "### IV.D.1. Vanilla Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853db323",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log, models_list_vanilla = model_training_and_evaluation(\n",
    "    models_list[\"vanilla\"],\n",
    "    \"baseline_model\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"vanilla\",\n",
    "    '../../models/logs/training_log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a23e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list[\"vanilla\"] = models_list_vanilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ac844f9",
   "metadata": {},
   "source": [
    "## IV.E. Models Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance that a model would achieve if it always predicted the most common label.\n",
    "benchmark = y_train.value_counts(normalize = True)[0]\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2eaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_logs_df = training_log_to_df_converter(training_log)\n",
    "all_training_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_best_model = best_model_finder(all_training_logs_df, models_list)\n",
    "baseline_best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0121273f",
   "metadata": {},
   "source": [
    "### IV.E.1. Confusion Matrix Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = baseline_best_model.predict(X_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556329eb-6f4a-45b8-a746-2084d4a06680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5ec57-4959-4932-b656-7b823cf1922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_prediction)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1b66e-25ae-4fb2-b3c1-6ee6e0231082",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bb2fc6d",
   "metadata": {},
   "source": [
    "### IV.E.2. Export Baseline Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../../models/baseline_best_model.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(baseline_best_model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de0ed9a4",
   "metadata": {},
   "source": [
    "## IV.F. Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be189d67",
   "metadata": {},
   "source": [
    "### IV.F.1. Hyperparameters List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7713f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparams = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"subsample\": [0.5, 0.7, 1],\n",
    "    \"colsample_bytree\": [0.5, 0.7, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_search = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_hyperparams, n_jobs = -1, verbose = 420)\n",
    "\n",
    "models_list[\"vanilla\"].append({\n",
    "    \"model_name\": xgb_grid_search.__class__.__name__ + \"-\" + xgb_grid_search.estimator.__class__.__name__,\n",
    "    \"model_object\": xgb_grid_search,\n",
    "    \"model_uid\": \"\"\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7943a5bb",
   "metadata": {},
   "source": [
    "### IV.F.2. Best Model Hyperparameter Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log, models_list_vanilla_tuned = model_training_and_evaluation(\n",
    "    [models_list[\"vanilla\"][-1]],\n",
    "    \"tuned_model\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"vanilla\",\n",
    "    '../../models/logs/training_log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c59ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list[\"vanilla\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f99ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_logs_df_tuned = training_log_to_df_converter(training_log)\n",
    "all_training_logs_df_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_best_model = best_model_finder(all_training_logs_df_tuned, models_list)\n",
    "tuned_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdea478-24b9-4dd0-820c-106337102e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = tuned_best_model.predict(X_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb67231-c406-42bd-b82f-5c39dafe02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44c44a6b",
   "metadata": {},
   "source": [
    "### IV.F.3. Export Hyperparameter-tuned Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../../models/tuned_best_model.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(tuned_best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
